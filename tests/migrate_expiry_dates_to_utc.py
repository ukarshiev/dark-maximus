#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –º–∏–≥—Ä–∞—Ü–∏–∏ –¥–∞—Ç expiry_date –≤ UTC

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏ –º–∏–≥—Ä–∏—Ä—É–µ—Ç –¥–∞—Ç—ã –≤ —Ç–∞–±–ª–∏—Ü–µ vpn_keys,
–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É—è –∏—Ö –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ (UTC+3) –≤ UTC.

–í–ê–ñ–ù–û: –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ —Ä–µ–∂–∏–º–µ dry-run (–Ω–µ –ø—Ä–∏–º–µ–Ω—è–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è)
–î–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–ª–∞–≥ --apply

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python tests/migrate_expiry_dates_to_utc.py                 # dry-run —Ä–µ–∂–∏–º
    python tests/migrate_expiry_dates_to_utc.py --apply         # –ø—Ä–∏–º–µ–Ω–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è
    python tests/migrate_expiry_dates_to_utc.py --analyze       # —Ç–æ–ª—å–∫–æ –∞–Ω–∞–ª–∏–∑
"""

import sys
import sqlite3
import argparse
from datetime import datetime, timezone, timedelta
from pathlib import Path
import shutil
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('tests/migration_expiry_dates.log'),
        logging.StreamHandler()
    ]
)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
DB_FILE = "users.db"
MOSCOW_TZ = timezone(timedelta(hours=3))
UTC = timezone.utc


def create_backup(db_path: Path) -> Path:
    """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –ë–î"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    backup_dir = Path("backups")
    backup_dir.mkdir(exist_ok=True)
    
    backup_path = backup_dir / f"users_{timestamp}_before_expiry_migration.db"
    shutil.copy2(db_path, backup_path)
    
    logging.info(f"‚úÖ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ–∑–¥–∞–Ω–∞: {backup_path}")
    return backup_path


def analyze_expiry_dates(db_path: Path) -> dict:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞—Ç—ã –≤ –ë–î –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–∞ –ª–∏ –º–∏–≥—Ä–∞—Ü–∏—è
    
    Returns:
        dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
    """
    logging.info("üîç –ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ –¥–∞—Ç –≤ –ë–î...")
    
    results = {
        'total_keys': 0,
        'active_keys': 0,
        'expired_keys': 0,
        'dates_analyzed': [],
        'need_migration': False,
        'estimated_offset_hours': 0
    }
    
    try:
        with sqlite3.connect(db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∫–ª—é—á–∏ —Å –¥–∞—Ç–∞–º–∏
            cursor.execute("""
                SELECT key_id, key_email, expiry_date, status, created_date
                FROM vpn_keys
                ORDER BY key_id
            """)
            
            rows = cursor.fetchall()
            results['total_keys'] = len(rows)
            
            if results['total_keys'] == 0:
                logging.warning("‚ö†Ô∏è –í –ë–î –Ω–µ—Ç –∫–ª—é—á–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
                return results
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –¥–∞—Ç—É
            now_utc = datetime.now(UTC)
            suspected_offset_hours = []
            
            for row in rows:
                key_id = row['key_id']
                expiry_str = row['expiry_date']
                status = row['status']
                
                if not expiry_str:
                    logging.warning(f"‚ö†Ô∏è –ö–ª—é—á {key_id}: expiry_date –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
                    continue
                
                # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —Ñ–æ—Ä–º–∞—Ç ISO –∏–ª–∏ Python default)
                try:
                    expiry_naive = datetime.fromisoformat(expiry_str.replace('Z', '+00:00'))
                    if expiry_naive.tzinfo:
                        expiry_naive = expiry_naive.replace(tzinfo=None)
                except ValueError:
                    try:
                        expiry_naive = datetime.strptime(expiry_str, '%Y-%m-%d %H:%M:%S')
                    except ValueError:
                        logging.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–∞—Ç—É –¥–ª—è –∫–ª—é—á–∞ {key_id}: {expiry_str}")
                        continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å
                is_active = status in ['trial-active', 'pay-active']
                if is_active:
                    results['active_keys'] += 1
                else:
                    results['expired_keys'] += 1
                
                # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –¥–∞—Ç–∞ –≤ –ë–î - —ç—Ç–æ UTC+3
                expiry_as_moscow = expiry_naive.replace(tzinfo=MOSCOW_TZ)
                expiry_as_utc_from_moscow = expiry_as_moscow.astimezone(UTC).replace(tzinfo=None)
                
                # –ò–ª–∏ –¥–∞—Ç–∞ —É–∂–µ –≤ UTC?
                expiry_as_utc = expiry_naive.replace(tzinfo=UTC)
                
                # –†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è–º–∏
                diff_hours = (expiry_as_utc_from_moscow - expiry_naive).total_seconds() / 3600
                
                results['dates_analyzed'].append({
                    'key_id': key_id,
                    'key_email': row['key_email'],
                    'expiry_naive': expiry_naive,
                    'expiry_as_moscow': expiry_as_utc_from_moscow,
                    'diff_hours': diff_hours,
                    'status': status
                })
                
                # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ offset
                if abs(diff_hours) > 0.1:  # –ï—Å–ª–∏ —Ä–∞–∑–Ω–∏—Ü–∞ –±–æ–ª—å—à–µ 6 –º–∏–Ω—É—Ç
                    suspected_offset_hours.append(diff_hours)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –Ω—É–∂–Ω–∞ –ª–∏ –º–∏–≥—Ä–∞—Ü–∏—è
            if suspected_offset_hours:
                avg_offset = sum(suspected_offset_hours) / len(suspected_offset_hours)
                results['estimated_offset_hours'] = round(avg_offset, 2)
                
                # –ï—Å–ª–∏ —Å—Ä–µ–¥–Ω–∏–π offset –±–ª–∏–∑–æ–∫ –∫ 3 —á–∞—Å–∞–º, –∑–Ω–∞—á–∏—Ç –¥–∞—Ç—ã –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
                if abs(avg_offset + 3) < 0.5:  # offset = -3 (–Ω—É–∂–Ω–æ –≤—ã—á–µ—Å—Ç—å 3 —á–∞—Å–∞)
                    results['need_migration'] = True
                    logging.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Å–º–µ—â–µ–Ω–∏–µ ~{avg_offset:.2f} —á–∞—Å–æ–≤ - –¥–∞—Ç—ã –≤–µ—Ä–æ—è—Ç–Ω–æ –≤ UTC+3")
                else:
                    logging.info(f"‚ÑπÔ∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Å–º–µ—â–µ–Ω–∏–µ {avg_offset:.2f} —á–∞—Å–æ–≤ - –Ω–µ—è—Å–Ω–æ, –Ω—É–∂–Ω–∞ –ª–∏ –º–∏–≥—Ä–∞—Ü–∏—è")
            
            logging.info(f"üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω:")
            logging.info(f"   - –í—Å–µ–≥–æ –∫–ª—é—á–µ–π: {results['total_keys']}")
            logging.info(f"   - –ê–∫—Ç–∏–≤–Ω—ã—Ö: {results['active_keys']}")
            logging.info(f"   - –ò—Å—Ç–µ–∫—à–∏—Ö: {results['expired_keys']}")
            logging.info(f"   - –û—Ü–µ–Ω–æ—á–Ω–æ–µ —Å–º–µ—â–µ–Ω–∏–µ: {results['estimated_offset_hours']} —á–∞—Å–æ–≤")
            logging.info(f"   - –ú–∏–≥—Ä–∞—Ü–∏—è –Ω—É–∂–Ω–∞: {'–î–ê' if results['need_migration'] else '–ù–ï–¢'}")
            
            return results
            
    except sqlite3.Error as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –ë–î: {e}")
        raise


def migrate_expiry_dates(db_path: Path, dry_run: bool = True) -> dict:
    """
    –ú–∏–≥—Ä–∏—Ä—É–µ—Ç –¥–∞—Ç—ã –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ (UTC+3) –≤ UTC
    
    Args:
        db_path: –ø—É—Ç—å –∫ –ë–î
        dry_run: –µ—Å–ª–∏ True, –Ω–µ –ø—Ä–∏–º–µ–Ω—è–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è
        
    Returns:
        dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –º–∏–≥—Ä–∞—Ü–∏–∏
    """
    results = {
        'total_migrated': 0,
        'failed': 0,
        'skipped': 0,
        'changes': []
    }
    
    mode_text = "DRY-RUN" if dry_run else "–ü–†–ò–ú–ï–ù–ï–ù–ò–ï"
    logging.info(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º –º–∏–≥—Ä–∞—Ü–∏—é ({mode_text})...")
    
    try:
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∫–ª—é—á–∏
            cursor.execute("""
                SELECT key_id, key_email, expiry_date, status
                FROM vpn_keys
                WHERE expiry_date IS NOT NULL
                ORDER BY key_id
            """)
            
            rows = cursor.fetchall()
            
            for row in rows:
                key_id, key_email, expiry_str, status = row
                
                try:
                    # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É
                    try:
                        expiry_naive = datetime.fromisoformat(expiry_str.replace('Z', '+00:00'))
                        if expiry_naive.tzinfo:
                            expiry_naive = expiry_naive.replace(tzinfo=None)
                    except ValueError:
                        expiry_naive = datetime.strptime(expiry_str, '%Y-%m-%d %H:%M:%S')
                    
                    # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –¥–∞—Ç–∞ –≤ –ë–î - —ç—Ç–æ UTC+3 (–ª–æ–∫–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è)
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ UTC: –≤—ã—á–∏—Ç–∞–µ–º 3 —á–∞—Å–∞
                    expiry_utc = expiry_naive - timedelta(hours=3)
                    
                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤ –ë–î
                    expiry_utc_str = expiry_utc.strftime('%Y-%m-%d %H:%M:%S')
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ
                    change = {
                        'key_id': key_id,
                        'key_email': key_email,
                        'old_date': expiry_str,
                        'new_date': expiry_utc_str,
                        'diff_hours': -3
                    }
                    results['changes'].append(change)
                    
                    if not dry_run:
                        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ
                        cursor.execute("""
                            UPDATE vpn_keys
                            SET expiry_date = ?
                            WHERE key_id = ?
                        """, (expiry_utc_str, key_id))
                        
                        logging.debug(f"‚úÖ –ö–ª—é—á {key_id}: {expiry_str} -> {expiry_utc_str}")
                    else:
                        logging.debug(f"üìù –ö–ª—é—á {key_id}: {expiry_str} -> {expiry_utc_str} (DRY-RUN)")
                    
                    results['total_migrated'] += 1
                    
                except Exception as e:
                    logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –º–∏–≥—Ä–∞—Ü–∏–∏ –∫–ª—é—á–∞ {key_id}: {e}")
                    results['failed'] += 1
            
            if not dry_run:
                conn.commit()
                logging.info("‚úÖ –ò–∑–º–µ–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î")
            else:
                logging.info("üìù DRY-RUN: –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã")
            
            logging.info(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–∏–≥—Ä–∞—Ü–∏–∏:")
            logging.info(f"   - –ú–∏–≥—Ä–∏—Ä–æ–≤–∞–Ω–æ: {results['total_migrated']}")
            logging.info(f"   - –û—à–∏–±–æ–∫: {results['failed']}")
            logging.info(f"   - –ü—Ä–æ–ø—É—â–µ–Ω–æ: {results['skipped']}")
            
            return results
            
    except sqlite3.Error as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –º–∏–≥—Ä–∞—Ü–∏–∏ –ë–î: {e}")
        raise


def print_analysis_report(results: dict):
    """–í—ã–≤–æ–¥–∏—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É"""
    print("\n" + "="*80)
    print("üìã –î–ï–¢–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –ê–ù–ê–õ–ò–ó–ê")
    print("="*80)
    
    print(f"\nüìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   - –í—Å–µ–≥–æ –∫–ª—é—á–µ–π: {results['total_keys']}")
    print(f"   - –ê–∫—Ç–∏–≤–Ω—ã—Ö: {results['active_keys']}")
    print(f"   - –ò—Å—Ç–µ–∫—à–∏—Ö: {results['expired_keys']}")
    print(f"   - –û—Ü–µ–Ω–æ—á–Ω–æ–µ —Å–º–µ—â–µ–Ω–∏–µ: {results['estimated_offset_hours']} —á–∞—Å–æ–≤")
    print(f"   - –ú–∏–≥—Ä–∞—Ü–∏—è –Ω—É–∂–Ω–∞: {'–î–ê ‚úÖ' if results['need_migration'] else '–ù–ï–¢ ‚ùå'}")
    
    if results['dates_analyzed']:
        print(f"\nüîç –ü—Ä–∏–º–µ—Ä—ã –¥–∞—Ç (–ø–µ—Ä–≤—ã–µ 5):")
        for i, item in enumerate(results['dates_analyzed'][:5], 1):
            print(f"\n   {i}. –ö–ª—é—á {item['key_id']} ({item['key_email']}):")
            print(f"      - –î–∞—Ç–∞ –≤ –ë–î (naive):     {item['expiry_naive']}")
            print(f"      - –ï—Å–ª–∏ —ç—Ç–æ UTC+3 -> UTC: {item['expiry_as_moscow']}")
            print(f"      - –†–∞–∑–Ω–∏—Ü–∞: {item['diff_hours']:.2f} —á–∞—Å–æ–≤")
            print(f"      - –°—Ç–∞—Ç—É—Å: {item['status']}")
    
    print("\n" + "="*80)


def main():
    parser = argparse.ArgumentParser(
        description='–ú–∏–≥—Ä–∞—Ü–∏—è –¥–∞—Ç expiry_date –≤ UTC',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    
    parser.add_argument(
        '--apply',
        action='store_true',
        help='–ü—Ä–∏–º–µ–Ω–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: dry-run)'
    )
    
    parser.add_argument(
        '--analyze',
        action='store_true',
        help='–¢–æ–ª—å–∫–æ –∞–Ω–∞–ª–∏–∑, –±–µ–∑ –º–∏–≥—Ä–∞—Ü–∏–∏'
    )
    
    parser.add_argument(
        '--db',
        default=DB_FILE,
        help=f'–ü—É—Ç—å –∫ –ë–î (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {DB_FILE})'
    )
    
    args = parser.parse_args()
    
    db_path = Path(args.db)
    
    if not db_path.exists():
        logging.error(f"‚ùå –ë–î –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {db_path}")
        sys.exit(1)
    
    print("\n" + "="*80)
    print("üîß –ú–ò–ì–†–ê–¶–ò–Ø EXPIRY_DATE –í UTC")
    print("="*80)
    
    # –ê–Ω–∞–ª–∏–∑
    analysis_results = analyze_expiry_dates(db_path)
    
    if args.analyze:
        print_analysis_report(analysis_results)
        return
    
    # –ï—Å–ª–∏ –º–∏–≥—Ä–∞—Ü–∏—è –Ω–µ –Ω—É–∂–Ω–∞, –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–µ–º
    if not analysis_results['need_migration']:
        print("\n‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑ –ø–æ–∫–∞–∑–∞–ª, —á—Ç–æ –º–∏–≥—Ä–∞—Ü–∏—è –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
        print("   –î–∞—Ç—ã –≤–µ—Ä–æ—è—Ç–Ω–æ —É–∂–µ –≤ UTC –∏–ª–∏ –∏–º–µ—é—Ç –¥—Ä—É–≥–æ–π —Ñ–æ—Ä–º–∞—Ç.")
        
        response = input("\n‚ùì –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –º–∏–≥—Ä–∞—Ü–∏—é? (yes/no): ").strip().lower()
        if response not in ['yes', 'y', '–¥–∞', '–¥']:
            print("‚ùå –ú–∏–≥—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            return
    
    # –°–æ–∑–¥–∞–µ–º –±—ç–∫–∞–ø (–µ—Å–ª–∏ –Ω–µ dry-run)
    if args.apply:
        create_backup(db_path)
    
    # –ú–∏–≥—Ä–∞—Ü–∏—è
    dry_run = not args.apply
    migration_results = migrate_expiry_dates(db_path, dry_run=dry_run)
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
    print("\n" + "="*80)
    print("‚úÖ –ú–ò–ì–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê")
    print("="*80)
    print(f"\n–†–µ–∂–∏–º: {'DRY-RUN (–∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã)' if dry_run else '–ü–†–ò–ú–ï–ù–ï–ù–û'}")
    print(f"–ú–∏–≥—Ä–∏—Ä–æ–≤–∞–Ω–æ: {migration_results['total_migrated']}")
    print(f"–û—à–∏–±–æ–∫: {migration_results['failed']}")
    
    if dry_run:
        print("\nüí° –î–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å —Ñ–ª–∞–≥–æ–º --apply:")
        print(f"   python {sys.argv[0]} --apply")
    else:
        print("\n‚úÖ –ò–∑–º–µ–Ω–µ–Ω–∏—è —É—Å–ø–µ—à–Ω–æ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã!")
        print(f"üì¶ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ –ø–∞–ø–∫–µ backups/")
    
    print("="*80 + "\n")


if __name__ == '__main__':
    main()

